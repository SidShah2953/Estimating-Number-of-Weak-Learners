{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the Iris dataset. \n",
    "\n",
    "Since we are representing our single classifier as a Bernoulli trial, this is a binary classification problem. The Iris dataset has three labels, so we drop the data that is labelled $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "iris = iris\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X = X[y != 0]\n",
    "y = y[y != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split it into training and testing sets of equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X,\n",
    "                        y, \n",
    "                        test_size=0.5, \n",
    "                        random_state=42)\n",
    "data = {\n",
    "    'X_train': X_train, \n",
    "    'X_test': X_test, \n",
    "    'y_train': y_train, \n",
    "    'y_test': y_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Equation $4.2$, we assumed $p_i$ are generated by a distribution with mean $\\mu_p$ and variance $\\sigma_p^2$.\n",
    "\n",
    "Thus, we need to estimate this distribution. We do so by generating $100$ random forests, each of size $1$ and getting the accuracy of each using the `approx_learner_dist` function, from the `ensembleEstimation` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94 0.76 0.9  0.94 0.86 0.9  0.7  0.7  0.94 0.9  0.94 0.94 0.9  0.94\n",
      " 0.86 0.94 0.4  0.76 0.94 0.9  0.9  0.44 0.88 0.9  0.88 0.44 0.68 0.94\n",
      " 0.88 0.86 0.88 0.88 0.88 0.94 0.66 0.68 0.9  0.68 0.88 0.86 0.88 0.88\n",
      " 0.94 0.86 0.88 0.68 0.88 0.94 0.86 0.68 0.6  0.68 0.86 0.88 0.86 0.92\n",
      " 0.94 0.88 0.88 0.92 0.76 0.4  0.9  0.9  0.9  0.86 0.88 0.94 0.94 0.7\n",
      " 0.9  0.94 0.92 0.88 0.94 0.9  0.88 0.72 0.72 0.94 0.44 0.88 0.9  0.88\n",
      " 0.94 0.9  0.9  0.94 0.9  0.94 0.94 0.9  0.94 0.86 0.4  0.7  0.9  0.86\n",
      " 0.94 0.72]\n"
     ]
    }
   ],
   "source": [
    "from ensembleEstimation import ensembleEstimation\n",
    "\n",
    "ensemble_1 = ensembleEstimation(1, data)\n",
    "probs = ensemble_1.approx_learner_dist()\n",
    "\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_p : 0.8370000000000001\n",
      "sigma_p : 0.13441354098453026\n"
     ]
    }
   ],
   "source": [
    "print(f'mu_p : {ensemble_1.mu_p}')\n",
    "print(f'sigma_p : {ensemble_1.sigma_p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, $\\mu_p$ and $\\sigma_p$ are fairly away from $0$, we need to use the normal approximation. Suppose we use ensembles of size $11$, $21$, $\\dots$, $51$.\n",
    "\n",
    "We store the actual and predicted accuracies in a Pandas DataFrame for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = []\n",
    "actual_acc = []\n",
    "pred_acc = []\n",
    "\n",
    "for N in range(11, 51 + 1, 10):\n",
    "    Ns.append(N)\n",
    "    actual_acc.append(ensemble_1.find_actual_accuracy(N))\n",
    "    pred_acc.append(ensemble_1.approximate(N, \"normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    {\n",
    "        'N': Ns,\n",
    "        'Actual Accuracy': actual_acc,\n",
    "        'Predicted Accuracy': pred_acc\n",
    "    }\n",
    ")\n",
    "results['Relative Error'] = (results['Predicted Accuracy'] - results['Actual Accuracy']) /results['Actual Accuracy'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_excel('Paper/tables/Section 4.xlsx', index=False)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
